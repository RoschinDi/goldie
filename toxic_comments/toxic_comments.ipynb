{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364b4d9a",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389863e3",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82f6b2",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузим и подготовим данные.\n",
    "2. Обучим разные модели. \n",
    "3. Сделаем выводы.\n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eaa53d",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0765923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_STATE = 121345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1439304f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#читаем и выводим первые 5 строк посмотреть\n",
    "df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c41973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#смотрим общую инфу\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b988e0b0",
   "metadata": {},
   "source": [
    "159к строк, пропусков нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935608fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#смотрим на кол-во явных дубликатов, если они есть\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb8269b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#грузим лексическую базу данных\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf3f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 58s, sys: 4.78 s, total: 9min 2s\n",
      "Wall time: 9min 3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation Why the edits make under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww ! He match this background colour I 'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man , I 'm really not try to edit war . It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>`` More I ca n't make any real suggestion on i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You , sir , be my hero . Any chance you rememb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation Why the edits make under my userna...      0\n",
       "1  D'aww ! He match this background colour I 'm s...      0\n",
       "2  Hey man , I 'm really not try to edit war . It...      0\n",
       "3  `` More I ca n't make any real suggestion on i...      0\n",
       "4  You , sir , be my hero . Any chance you rememb...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#инициализируем лемматизатор\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#пишем функцию, которая поможет нам лемматизировать комментарии\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    lemmas = []\n",
    "    for token, pos in pos_tags:\n",
    "        wn_pos = get_wordnet_pos(pos)\n",
    "        lemmas.append(lemmatizer.lemmatize(token, pos=wn_pos))\n",
    "    lemmatized_text = ' '.join(lemmas)\n",
    "    return lemmatized_text\n",
    "\n",
    "#функция для преобразования POS-тега в формат WordNet\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return 'a'  \n",
    "    elif pos_tag.startswith('V'):\n",
    "        return 'v'  \n",
    "    elif pos_tag.startswith('N'):\n",
    "        return 'n'  \n",
    "    elif pos_tag.startswith('R'):\n",
    "        return 'r'  \n",
    "    else:\n",
    "        return 'n'  \n",
    "    \n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "\n",
    "#посмотрим, что получилось\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00615553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i ca n t make any real suggestion on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits make under my userna...      0\n",
       "1  d aww he match this background colour i m seem...      0\n",
       "2  hey man i m really not try to edit war it s ju...      0\n",
       "3  more i ca n t make any real suggestion on impr...      0\n",
       "4  you sir be my hero any chance you remember wha...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#напишем функцию для очистки лемматизированных комментариев от спец. символов\n",
    "def clear_text(text):\n",
    "    retext = text.lower()\n",
    "    retext = re.sub(r'[^a-zA-Z]', ' ', retext)\n",
    "    retext = retext.split()\n",
    "    return \" \".join(retext)\n",
    "\n",
    "df['text'] = df['text'].apply(clear_text)\n",
    "\n",
    "#посмотрим, что получилось\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d9cf8",
   "metadata": {},
   "source": [
    "Вывод: \n",
    "1. Пропусков и дубликатов не выявлено.\n",
    "2. Проведена лемматизация комментариев \n",
    "3. Проведена очистка от спец символов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7748bc63",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f02e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#список стоп-слов английского\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7827becb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95575, 119153)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(31858, 119153)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(31859, 119153)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(95575,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(31858,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(31859,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#выделим признаки и целевой признак \n",
    "\n",
    "features = df.drop(['toxic'], axis=1)\n",
    "target = df['toxic']\n",
    "\n",
    "\n",
    "\n",
    "#разобьем признаки и целевой признак на 2 группы, отделив обучающие данные от тестовых + валидационных\n",
    "features_train, features_valid_test, target_train, target_valid_test = train_test_split(\n",
    "    features, target, test_size=0.40, random_state=RANDOM_STATE, stratify=target)\n",
    "\n",
    "#затем разобьем вторую группу пополам: одни данные будут валидационными, другие - тестовыми \n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_valid_test, target_valid_test, test_size=0.50, random_state=RANDOM_STATE, stratify=target_valid_test)\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train['text'])\n",
    "features_valid = count_tf_idf.transform(features_valid['text'])\n",
    "features_test = count_tf_idf.transform(features_test['text'])\n",
    "\n",
    "#проверим\n",
    "display(features_train.shape)\n",
    "display(features_valid.shape)\n",
    "display(features_test.shape)\n",
    "display(target_train.shape)\n",
    "display(target_valid.shape)\n",
    "display(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf3cda",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7ecbe9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Наилучшие гиперпараметры:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 4, 'penalty': 'l1', 'random_state': 121345}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1-метрика:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7677052274970287"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 1min 12s, total: 2min 31s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr = LogisticRegression(random_state=RANDOM_STATE, solver='liblinear')\n",
    "\n",
    "param_grid = [{\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': list(range(1,15,3)),\n",
    "    'random_state': [RANDOM_STATE]\n",
    "}] \n",
    "\n",
    "\n",
    "grid = GridSearchCV(model_lr, param_grid=param_grid, scoring='f1', cv=3, verbose=True)\n",
    "best_grid = grid.fit(features_train, target_train)\n",
    "display(\"Наилучшие гиперпараметры:\", grid.best_params_)\n",
    "display(\"F1-метрика:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e26412",
   "metadata": {},
   "source": [
    "Обучим случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f457a24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Наилучшие гиперпараметры:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 50, 'n_estimators': 1, 'random_state': 121345}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1-метрика:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.27614748821703833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 46s, sys: 1.13 s, total: 5min 47s\n",
      "Wall time: 5min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params_forest = {\n",
    "    'n_estimators': [1,50, 100],\n",
    "    'max_depth': [1,10,50],\n",
    "    'random_state':[RANDOM_STATE]\n",
    "}\n",
    "\n",
    "model_forest = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "                                 \n",
    "grid = GridSearchCV(model_forest, param_grid=params_forest, scoring='f1', cv=3, verbose=True)\n",
    "best_grid = grid.fit(features_train, target_train)\n",
    "display(\"Наилучшие гиперпараметры:\", grid.best_params_)\n",
    "display(\"F1-метрика:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f4b327",
   "metadata": {},
   "source": [
    "Обучим дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c77e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Наилучшие гиперпараметры:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'random_state': 121345}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1-метрика:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.587727848937947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.3 s, sys: 146 ms, total: 31.4 s\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params_tree = {\n",
    "    'max_depth': [1,10],\n",
    "    'random_state':[RANDOM_STATE]\n",
    "}\n",
    "\n",
    "model_tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "                                 \n",
    "grid = GridSearchCV(model_tree, param_grid=params_tree, scoring='f1', cv=3, verbose=True)\n",
    "best_grid = grid.fit(features_train, target_train)\n",
    "display(\"Наилучшие гиперпараметры:\", grid.best_params_)\n",
    "display(\"F1-метрика:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f86ae",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadf198c",
   "metadata": {},
   "source": [
    "Лучшее значение f1 дала модель логистической регрессии, поэтому ее и протестируем на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5967f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.776563033823027"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression(C=4, penalty='l1', random_state=RANDOM_STATE, solver='liblinear')\n",
    "model_lr.fit(features_train, target_train)\n",
    "predict_lr = model_lr.predict(features_test)\n",
    "f1_lr = f1_score(predict_lr, target_test)\n",
    "f1_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb560276",
   "metadata": {},
   "source": [
    "Вывод: \n",
    "\n",
    "На первом этапе мы загрузили и подготовили данные для обучения моделей. Затем мы очистили и лемматизировали тексты комментариев.\n",
    "\n",
    "Для моделирования мы использовали Логистическую регрессию, Случайный лес и Дерево решений. После подбора гиперпараметров и обучения моделей, модель логистической регрессии показала наилучший результат, а Случайный лес - наихудший.\n",
    "\n",
    "В связи с этим, как решение для данной задачи, модели Логистическая регрессия подходит. На тестовой выборке логистическая регрессия показала значени метрики f1 ~ 0.78.\n",
    "\n",
    "p.s.\n",
    "Попробовал только самые легкие модели, т.к. сейчас нет к сожалению возможности работать локально, а на сайте от бустинговых моделей ядро умирает. Берта тоже к сожалению не могу сейчас опробовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4cf29f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
